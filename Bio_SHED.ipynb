{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BioSHED05/BioShed/blob/main/Bio_SHED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLPo6KboTgHh",
        "outputId": "6a7d775a-f3b6-4eda-cab1-1775ed6beb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scanpy in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: decoupler in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Requirement already satisfied: igraph in /usr/local/lib/python3.11/dist-packages (0.11.9)\n",
            "Requirement already satisfied: leidenalg in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: anndata>=0.8 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.12.1)\n",
            "Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.5.1)\n",
            "Requirement already satisfied: legacy-api-wrap>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.4.1)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7.1 in /usr/local/lib/python3.11/dist-packages (from scanpy) (3.5)\n",
            "Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.11/dist-packages (from scanpy) (2.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scanpy) (25.0)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from scanpy) (2.2.2)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.5.13)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from scanpy) (1.15.3)\n",
            "Requirement already satisfied: session-info2 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.2)\n",
            "Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from scanpy) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from scanpy) (4.14.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from scanpy) (0.5.9.post2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: adjusttext in /usr/local/lib/python3.11/dist-packages (from decoupler) (1.3.0)\n",
            "Requirement already satisfied: docrep in /usr/local/lib/python3.11/dist-packages (from decoupler) (0.3.2)\n",
            "Requirement already satisfied: marsilea in /usr/local/lib/python3.11/dist-packages (from decoupler) (0.5.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from decoupler) (2.32.3)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from igraph) (1.7.0)\n",
            "Requirement already satisfied: array-api-compat>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8->scanpy) (1.12.0)\n",
            "Requirement already satisfied: zarr!=3.0.*,>=2.18.7 in /usr/local/lib/python3.11/dist-packages (from anndata>=0.8->scanpy) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.1->scanpy) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->scanpy) (3.6.0)\n",
            "Requirement already satisfied: legendkit in /usr/local/lib/python3.11/dist-packages (from marsilea->decoupler) (0.3.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from marsilea->decoupler) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->decoupler) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->decoupler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->decoupler) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->decoupler) (2025.8.3)\n",
            "Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.11/dist-packages (from zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy) (0.8.1.post1)\n",
            "Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.11/dist-packages (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy) (0.16.1)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from pandas[parquet]->marsilea->decoupler) (18.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from donfig>=0.8->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy) (6.0.2)\n",
            "Requirement already satisfied: crc32c>=2.7 in /usr/local/lib/python3.11/dist-packages (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy) (2.7.1)\n",
            "--2025-08-07 21:48:25--  ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE72nnn/GSE72857/suppl/GSE72857_umitab.txt.gz\n",
            "           => ‚ÄòGSE72857_umitab.txt.gz.1‚Äô\n",
            "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.7, 130.14.250.11, 130.14.250.12, ...\n",
            "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.7|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /geo/series/GSE72nnn/GSE72857/suppl ... done.\n",
            "==> SIZE GSE72857_umitab.txt.gz ... 16413252\n",
            "==> PASV ... done.    ==> RETR GSE72857_umitab.txt.gz ... done.\n",
            "Length: 16413252 (16M) (unauthoritative)\n",
            "\n",
            "GSE72857_umitab.txt 100%[===================>]  15.65M  21.4MB/s    in 0.7s    \n",
            "\n",
            "2025-08-07 21:48:27 (21.4 MB/s) - ‚ÄòGSE72857_umitab.txt.gz.1‚Äô saved [16413252]\n",
            "\n",
            "gzip: GSE72857_umitab.txt already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n",
            "AnnData object with n_obs √ó n_vars = 10368 √ó 27297\n",
            "WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.\n",
            "7    -1.487575\n",
            "10   -1.151510\n",
            "0    -1.263019\n",
            "1    -1.060151\n",
            "3    -0.945782\n",
            "11   -1.203438\n",
            "9    -1.061269\n",
            "2    -1.134718\n",
            "12   -1.358760\n",
            "5    -1.183962\n",
            "8    -1.034637\n",
            "6    -0.998487\n",
            "4    -0.950339\n",
            "Name: SEI, dtype: float32\n"
          ]
        }
      ],
      "source": [
        "# üì¶ Install required packages\n",
        "!pip install scanpy seaborn matplotlib decoupler igraph leidenalg\n",
        "\n",
        "# üì• Download and unzip the dataset\n",
        "!wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE72nnn/GSE72857/suppl/GSE72857_umitab.txt.gz\n",
        "!gunzip GSE72857_umitab.txt.gz\n",
        "\n",
        "# üß¨ Load the dataset efficiently\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read in chunks using pandas and convert to a sparse matrix directly\n",
        "# This avoids loading the entire dense dataframe into memory\n",
        "df_iterator = pd.read_csv(\"GSE72857_umitab.txt\", sep=\"\\t\", index_col=0, chunksize=10000)\n",
        "chunks = []\n",
        "for chunk in df_iterator:\n",
        "    chunks.append(chunk)\n",
        "\n",
        "df = pd.concat(chunks)\n",
        "\n",
        "# Convert to sparse matrix before creating AnnData object\n",
        "from scipy.sparse import csr_matrix\n",
        "adata = sc.AnnData(csr_matrix(df.T.values), obs=pd.DataFrame(index=df.columns), var=pd.DataFrame(index=df.index))\n",
        "\n",
        "print(adata)\n",
        "\n",
        "# üîç Preprocessing\n",
        "sc.pp.filter_cells(adata, min_genes=200)\n",
        "sc.pp.filter_genes(adata, min_cells=3)\n",
        "sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "sc.pp.log1p(adata)\n",
        "\n",
        "# üìâ Dimensionality reduction\n",
        "sc.pp.pca(adata)\n",
        "sc.pp.neighbors(adata)\n",
        "sc.tl.umap(adata)\n",
        "sc.tl.leiden(adata, resolution=0.5)\n",
        "\n",
        "# üïí Pseudotime estimation\n",
        "# üß† Bio-SHED: Symbolic Emergence Index (SEI)\n",
        "def compute_sei(adata, groupby=\"leiden\"):\n",
        "    sei_scores = {}\n",
        "    for group in adata.obs[groupby].unique():\n",
        "        group_adata = adata[adata.obs[groupby] == group] # Use a new variable for the subset\n",
        "        expr = group_adata.X.toarray() if hasattr(group_adata.X, \"toarray\") else group_adata.X\n",
        "        # Use a small epsilon to avoid log(0) and handle potential zeros after normalization\n",
        "        entropy = -np.sum((expr / (expr.sum(axis=1, keepdims=True) + 1e-8)) * np.log1p(expr + 1e-8), axis=1)\n",
        "        sei_scores[group] = np.mean(entropy)\n",
        "    return pd.Series(sei_scores, name=\"SEI\")\n",
        "\n",
        "sei = compute_sei(adata)\n",
        "adata.obs[\"sei\"] = adata.obs[\"leiden\"].map(sei)\n",
        "\n",
        "# Find the leiden cluster with the minimum average SEI score\n",
        "min_sei_cluster = sei.idxmin()\n",
        "\n",
        "# Find the cell with the minimum pseudotime within the minimum SEI cluster\n",
        "# Since dpt_pseudotime was not computed, we will approximate the root cell\n",
        "# by finding the cell in the minimum SEI cluster with the smallest index\n",
        "# as a proxy for early cells. This is a heuristic and might need adjustment\n",
        "# based on biological knowledge.\n",
        "root_cell_index = adata[adata.obs[\"leiden\"] == min_sei_cluster].obs_names[0]\n",
        "\n",
        "# Set the root cell\n",
        "adata.uns['iroot'] = adata.obs_names.get_loc(root_cell_index)\n",
        "\n",
        "sc.tl.dpt(adata)\n",
        "\n",
        "sei.to_csv(\"sei_scores.csv\")\n",
        "print(sei)\n",
        "\n",
        "# üîÑ Bio-SHED: Kinetic Transition Detection\n",
        "def detect_transitions(adata, pseudotime_key=\"dpt_pseudotime\", top_n=100):\n",
        "    pt = adata.obs[pseudotime_key]\n",
        "    # Ensure that pt is sorted to calculate gradient correctly\n",
        "    sorted_indices = np.argsort(pt.values)\n",
        "    pt_sorted = pt.iloc[sorted_indices]\n",
        "    expr = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
        "    expr_sorted = expr[sorted_indices, :]\n",
        "\n",
        "    # Calculate gradient and replace NaNs and inf with 0 or a small number\n",
        "    d_expr = np.gradient(expr_sorted, pt_sorted.values, axis=0)\n",
        "    d_expr = np.nan_to_num(d_expr, nan=0.0, posinf=1e-8, neginf=-1e-8)\n",
        "\n",
        "\n",
        "    kinetic_scores = np.std(d_expr, axis=0)\n",
        "\n",
        "    # Create a DataFrame and filter out rows with NaN kinetic_scores before sorting\n",
        "    transitions_df = pd.DataFrame({\"gene\": adata.var_names, \"kinetic_score\": kinetic_scores})\n",
        "    transitions_df = transitions_df.dropna(subset=['kinetic_score'])\n",
        "\n",
        "    # Sort and select top genes\n",
        "    top_genes_df = transitions_df.sort_values(\"kinetic_score\", ascending=False).head(top_n)\n",
        "\n",
        "    return top_genes_df\n",
        "\n",
        "transitions = detect_transitions(adata)\n",
        "transitions.to_csv(\"kinetic_transitions.csv\", index=False)\n",
        "print(transitions.head())\n",
        "\n",
        "# üß¨ Bio-SHED: Motif Enrichment with DoRothEA\n",
        "import decoupler as dc\n",
        "\n",
        "# Load DoRothEA regulons using load_regulon\n",
        "dorothea = dc.dot.load_regulon('mouse', minsize=5, min_confidence=0.6) # Using mouse as the data is from mouse\n",
        "\n",
        "emergent_expr = adata[:, transitions[\"gene\"]].to_df().T\n",
        "\n",
        "# Process emergent_expr in chunks for decoupler to save memory\n",
        "results, norm_acts = dc.run_mlm(mat=emergent_expr, net=dorothea, source='source', target='target', verbose=True, use_chunked=True, chunk_size=1000)\n",
        "results.to_csv(\"dorothea_enrichment.csv\")\n",
        "print(results.head())\n",
        "\n",
        "# üìä Visualizations\n",
        "\n",
        "# 1. SEI on UMAP\n",
        "sc.pl.umap(adata, color=\"sei\", cmap=\"plasma\", title=\"Symbolic Emergence Index (SEI) on UMAP\")\n",
        "\n",
        "# 2. Emergent Gene Dynamics Across Pseudotime\n",
        "adata.obs[\"pt_bin\"] = pd.qcut(adata.obs[\"dpt_pseudotime\"], q=10, labels=False, duplicates='drop') # Add duplicates='drop'\n",
        "emergent_genes = transitions[\"gene\"]\n",
        "heatmap_data = adata[:, emergent_genes].to_df().groupby(adata.obs[\"pt_bin\"]).mean()\n",
        "sns.heatmap(heatmap_data.T, cmap=\"mako\", xticklabels=True)\n",
        "plt.xlabel(\"Pseudotime Bin\")\n",
        "plt.ylabel(\"Emergent Genes\")\n",
        "plt.title(\"Expression Dynamics of Emergent Genes Across Pseudotime\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Top Emergent Gene on UMAP\n",
        "top_gene = transitions[\"gene\"].iloc[0]\n",
        "sc.pl.umap(adata, color=top_gene, cmap=\"viridis\", title=f\"Expression of Emergent Gene: {top_gene}\")\n",
        "\n",
        "# 4. SEI vs Pseudotime\n",
        "sns.scatterplot(x=adata.obs[\"dpt_pseudotime\"], y=adata.obs[\"sei\"], hue=adata.obs[\"leiden\"], palette=\"viridis\")\n",
        "plt.xlabel(\"Pseudotime\")\n",
        "plt.ylabel(\"SEI\")\n",
        "plt.title(\"Symbolic Emergence Index Across Differentiation Trajectory\")\n",
        "plt.show()\n",
        "\n",
        "# 5. Motif Enrichment Bubble Plot\n",
        "sns.scatterplot(data=results.sort_values(\"score\", ascending=False).head(20),\n",
        "                x=\"source\", y=\"score\", size=-np.log10(results[\"p_value\"].head(20)),\n",
        "                hue=\"score\", palette=\"coolwarm\", legend=False)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Top Enriched TFs in Emergent Genes\")\n",
        "plt.ylabel(\"Enrichment Score\")\n",
        "plt.show()\n",
        "\n",
        "# üìÅ Download results\n",
        "# from google.colab import files\n",
        "# files.download(\"sei_scores.csv\")\n",
        "# files.download(\"kinetic_transitions.csv\")\n",
        "# files.download(\"dorothea_enrichment.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44479543"
      },
      "source": [
        "# Task\n",
        "Explain the error in the selected code. If possible, fix the error and incorporate the changes into the existing code. Otherwise, try to diagnose the error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caa35141"
      },
      "source": [
        "## Identify emergent genes\n",
        "\n",
        "### Subtask:\n",
        "Extract the list of emergent genes from the previous analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15eba142"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the \"kinetic_transitions.csv\" file into a pandas DataFrame and extract the 'gene' column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97906720"
      },
      "outputs": [],
      "source": [
        "transitions_df = pd.read_csv(\"kinetic_transitions.csv\")\n",
        "emergent_genes = transitions_df[\"gene\"].tolist()\n",
        "print(emergent_genes[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45781018"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because the pandas library was not imported. Import pandas and then load the \"kinetic_transitions.csv\" file into a pandas DataFrame and extract the 'gene' column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Rogmhb1t0T-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "transitions_df = pd.read_csv(\"kinetic_transitions.csv\")\n",
        "emergent_genes = transitions_df[\"gene\"].tolist()\n",
        "print(emergent_genes[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20e83b66"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because the file \"kinetic_transitions.csv\" was not found. This is likely because the previous cell that created and saved this file did not execute successfully. I will re-run the code from the previous cell that generates and saves the \"kinetic_transitions.csv\" file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0Z8LWtvt3Zc"
      },
      "outputs": [],
      "source": [
        "# üß¨ Bio-SHED: Kinetic Transition Detection\n",
        "def detect_transitions(adata, pseudotime_key=\"dpt_pseudotime\", top_n=100):\n",
        "    pt = adata.obs[pseudotime_key]\n",
        "    # Ensure that pt is sorted to calculate gradient correctly\n",
        "    sorted_indices = np.argsort(pt.values)\n",
        "    pt_sorted = pt.iloc[sorted_indices]\n",
        "    expr = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
        "    expr_sorted = expr[sorted_indices, :]\n",
        "    d_expr = np.gradient(expr_sorted, pt_sorted.values, axis=0)\n",
        "    kinetic_scores = np.std(d_expr, axis=0)\n",
        "    top_genes = adata.var_names[np.argsort(kinetic_scores)[-top_n:]]\n",
        "    return pd.DataFrame({\"gene\": top_genes, \"kinetic_score\": kinetic_scores[np.argsort(kinetic_scores)[-top_n:]]})\n",
        "\n",
        "transitions = detect_transitions(adata)\n",
        "transitions.to_csv(\"kinetic_transitions.csv\", index=False)\n",
        "print(transitions.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "112bfd53"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because the `adata` object was not defined. The `adata` object is created and preprocessed in the original notebook code. I will include the code that creates and preprocesses the `adata` object, computes pseudotime, and then compute and save the kinetic transitions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW8sX--Wt7Pj"
      },
      "outputs": [],
      "source": [
        "# Load the dataset efficiently using dask\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import numpy as np\n",
        "\n",
        "# Read in chunks using pandas and convert to a sparse matrix directly\n",
        "# This avoids loading the entire dense dataframe into memory\n",
        "df_iterator = pd.read_csv(\"GSE72857_umitab.txt\", sep=\"\\t\", index_col=0, chunksize=10000)\n",
        "chunks = []\n",
        "for chunk in df_iterator:\n",
        "    chunks.append(chunk)\n",
        "\n",
        "df = pd.concat(chunks)\n",
        "\n",
        "# Convert to sparse matrix before creating AnnData object\n",
        "from scipy.sparse import csr_matrix\n",
        "adata = sc.AnnData(csr_matrix(df.T.values), obs=pd.DataFrame(index=df.columns), var=pd.DataFrame(index=df.index))\n",
        "\n",
        "# üîç Preprocessing\n",
        "sc.pp.filter_cells(adata, min_genes=200)\n",
        "sc.pp.filter_genes(adata, min_cells=3)\n",
        "sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "sc.pp.log1p(adata)\n",
        "\n",
        "# üìâ Dimensionality reduction\n",
        "sc.pp.pca(adata)\n",
        "sc.pp.neighbors(adata)\n",
        "sc.tl.umap(adata)\n",
        "sc.tl.leiden(adata, resolution=0.5)\n",
        "\n",
        "# üïí Pseudotime estimation\n",
        "# üß† Bio-SHED: Symbolic Emergence Index (SEI)\n",
        "def compute_sei(adata, groupby=\"leiden\"):\n",
        "    sei_scores = {}\n",
        "    for group in adata.obs[groupby].unique():\n",
        "        cells = adata[adata.obs[groupby] == group]\n",
        "        expr = cells.X.toarray() if hasattr(cells.X, \"toarray\") else cells.X\n",
        "        # Use a small epsilon to avoid log(0) and handle potential zeros after normalization\n",
        "        entropy = -np.sum((expr / (expr.sum(axis=1, keepdims=True) + 1e-8)) * np.log1p(expr + 1e-8), axis=1)\n",
        "        sei_scores[group] = np.mean(entropy)\n",
        "    return pd.Series(sei_scores, name=\"SEI\")\n",
        "\n",
        "sei = compute_sei(adata)\n",
        "adata.obs[\"sei\"] = adata.obs[\"leiden\"].map(sei)\n",
        "\n",
        "# Find the leiden cluster with the minimum average SEI score\n",
        "min_sei_cluster = sei.idxmin()\n",
        "\n",
        "# Find the cell with the minimum pseudotime within the minimum SEI cluster\n",
        "# Since dpt_pseudotime was not computed, we will approximate the root cell\n",
        "# by finding the cell in the minimum SEI cluster with the smallest index\n",
        "# as a proxy for early cells. This is a heuristic and might need adjustment\n",
        "# based on biological knowledge.\n",
        "root_cell_index = adata[adata.obs[\"leiden\"] == min_sei_cluster].obs_names[0]\n",
        "\n",
        "# Set the root cell\n",
        "adata.uns['iroot'] = adata.obs_names.get_loc(root_cell_index)\n",
        "\n",
        "sc.tl.dpt(adata)\n",
        "\n",
        "\n",
        "# üîÑ Bio-SHED: Kinetic Transition Detection\n",
        "def detect_transitions(adata, pseudotime_key=\"dpt_pseudotime\", top_n=100):\n",
        "    pt = adata.obs[pseudotime_key]\n",
        "    # Ensure that pt is sorted to calculate gradient correctly\n",
        "    sorted_indices = np.argsort(pt.values)\n",
        "    pt_sorted = pt.iloc[sorted_indices]\n",
        "    expr = adata.X.toarray() if hasattr(adata.X, \"toarray\") else adata.X\n",
        "    expr_sorted = expr[sorted_indices, :]\n",
        "\n",
        "    # Calculate gradient and replace NaNs and inf with 0 or a small number\n",
        "    d_expr = np.gradient(expr_sorted, pt_sorted.values, axis=0)\n",
        "    d_expr = np.nan_to_num(d_expr, nan=0.0, posinf=1e-8, neginf=-1e-8)\n",
        "\n",
        "    kinetic_scores = np.std(d_expr, axis=0)\n",
        "\n",
        "    # Create a DataFrame and filter out rows with NaN kinetic_scores before sorting\n",
        "    transitions_df = pd.DataFrame({\"gene\": adata.var_names, \"kinetic_score\": kinetic_scores})\n",
        "    transitions_df = transitions_df.dropna(subset=['kinetic_score'])\n",
        "\n",
        "    # Sort and select top genes\n",
        "    top_genes_df = transitions_df.sort_values(\"kinetic_score\", ascending=False).head(top_n)\n",
        "\n",
        "    return top_genes_df\n",
        "\n",
        "transitions = detect_transitions(adata)\n",
        "transitions.to_csv(\"kinetic_transitions.csv\", index=False)\n",
        "print(transitions.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNconN2SoDKGavLsKoxSCMR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}